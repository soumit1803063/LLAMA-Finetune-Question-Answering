{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Login Hugging Face</b></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: cuda\n",
      "Logged in to Hugging Face Hub successfully.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device set to: {DEVICE}\")\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF\")\n",
    "login(token=HF_TOKEN)\n",
    "print(\"Logged in to Hugging Face Hub successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Settings</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL_PATH=\"data/model/Fine_Tuned_LLaMA2\"\n",
    "DATA_FILE_PATH = \"data/syntheses_10.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Store Finatial Data (Evidence) To Vector Database</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Functions</b></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from uuid import uuid4\n",
    "\n",
    "def get_data_to_store_in_chromaDB(file_path: str) -> pd.DataFrame:\n",
    "    # Load data from a CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[['evidence_text']]\n",
    "    return df\n",
    "\n",
    "def store_to_chromaDB(df:pd.DataFrame, \n",
    "                      collection_name: str, \n",
    "                      database_path:str):\n",
    "    # Initialize the client\n",
    "    client = chromadb.PersistentClient(database_path)\n",
    "    \n",
    "    # Get or create the collection\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "\n",
    "    # If the collection is empty, add the documents\n",
    "    if not collection.count():\n",
    "        for _, row in df.iterrows():\n",
    "            # Add document to collection with a unique ID\n",
    "            collection.add(\n",
    "                documents=row['evidence_text'],  # Ensure the column name is correct\n",
    "                ids=[str(uuid4())]  # Generate a unique ID using uuid4\n",
    "            )\n",
    "    print(f\"Financial Data added to collection '{collection_name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Pipeline</b></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_store_pipeline(source_data_path:str='data/syntheses_10.csv',\n",
    "                        collection_name: str=\"FinancialData\", \n",
    "                        database_path:str=\"data/vetorstore\"):\n",
    "    \n",
    "    data_to_store_in_chromaDB = get_data_to_store_in_chromaDB(file_path=source_data_path)\n",
    "    store_to_chromaDB(df=data_to_store_in_chromaDB,\n",
    "                      collection_name=collection_name,\n",
    "                      database_path=database_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>Execute Pipeline</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Data added to collection 'FinancialData'.\n"
     ]
    }
   ],
   "source": [
    "data_store_pipeline(source_data_path='data/syntheses_10.csv',\n",
    "                                 collection_name=\"FinancialData\",\n",
    "                                 database_path=\"data/DB/vetorstore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Load the Finetuned Model</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Functions</b></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from typing import Any\n",
    "\n",
    "def get_bnb_config(load_in_4bit: bool = True,\n",
    "                   bnb_4bit_use_double_quant: bool = True,\n",
    "                   bnb_4bit_quant_type: str = \"nf4\",\n",
    "                   bnb_4bit_compute_dtype: Any = torch.bfloat16\n",
    "                   ) -> BitsAndBytesConfig:\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=load_in_4bit,# Whether to load model in 4-bit precision\n",
    "        bnb_4bit_use_double_quant=bnb_4bit_use_double_quant, # Whether to use double quantization\n",
    "        bnb_4bit_quant_type=bnb_4bit_quant_type,# The quantization type (e.g., \"nf4\")\n",
    "        bnb_4bit_compute_dtype=bnb_4bit_compute_dtype# The compute dtype (e.g., torch.bfloat16, torch.float16)\n",
    "    )\n",
    "    return bnb_config\n",
    "\n",
    "def get_model(model_path: str,\n",
    "              bnb_config: BitsAndBytesConfig,\n",
    "              device:str):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                                 quantization_config=bnb_config,\n",
    "                                                 device_map = \"auto\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_tokenizer(model_path: str, device: str) -> tuple:\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Pipeline</b></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_preparation_pipeline(model_path:str,\n",
    "                               device:str\n",
    "                                ):\n",
    "    \n",
    "    bnb_config = get_bnb_config()\n",
    "    model = get_model(model_path=model_path,\n",
    "                      bnb_config=bnb_config,\n",
    "                      device=device)\n",
    "    tokenizer = get_tokenizer(model_path=model_path,\n",
    "                              device=device)\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>Execute Pipeline</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model, finetuned_tokenizer = model_preparation_pipeline(model_path=FINETUNED_MODEL_PATH,\n",
    "                                                                device=DEVICE)\n",
    "print(f\"Got Finetuned Model.\")\n",
    "print(f\"Got Finetuned Tokenizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Generate Answer From LLM</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Functions</b></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    # Load data from a CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    if 'syntheses' in data.columns:\n",
    "        data.drop(\"syntheses\", axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def create_single_prompt(data_series: pd.Series) -> str:\n",
    "        \n",
    "        system_prompt = \"\"\"Give answer to questions provided below from the evidence text.\"\"\"\n",
    "        prompt_template = \"\"\"\n",
    "        <s>[INST]\n",
    "        <<SYS>>\n",
    "        {system_prompt}\n",
    "        <</SYS>>\n",
    "\n",
    "        Here is the question:\n",
    "        {question}\n",
    "\n",
    "        Consider the provided text as evidence:\n",
    "        {evidence_text}\n",
    "        [/INST]\n",
    "        \"\"\"\n",
    "        single_prompt = prompt_template.format(\n",
    "            system_prompt=system_prompt,  \n",
    "            question=data_series[\"question\"],  \n",
    "            evidence_text=data_series[\"evidence_text\"]  \n",
    "        )\n",
    "    \n",
    "        return single_prompt\n",
    "\n",
    "def generate(prompt,model,tokenizer,max_new_tokens: int = 100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate response\n",
    "    output = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Decode the response\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "def extract_answer(generated_text):\n",
    "    # Extract the Answer Portion from the whole generated text\n",
    "    answer_start = generated_text.find(\"[/INST]\") + len(\"[/INST]\")  # Find the end of </INST> tag\n",
    "    answer = generated_text[answer_start:].strip()  # Extract everything after that position\n",
    "    return answer    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Pipeline</b></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_pipeline(singe_data_series,\n",
    "                             model,\n",
    "                             tokenizer):\n",
    "    single_prompt = create_single_prompt(singe_data_series)\n",
    "    generated_text = generate(single_prompt,model,tokenizer)\n",
    "    answer = extract_answer(generated_text)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>Execute Pipeline</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = load_data(file_path=DATA_FILE_PATH)\n",
    "single_dataseries = dataframe.iloc[0]\n",
    "generated_answer = generate_answer_pipeline(single_dataseries,\n",
    "                                            finetuned_model,\n",
    "                                            finetuned_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>Query with the Generated Answer in ChromaDB</b></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>Prepare Function</b></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def query_collection(generated_answer, \n",
    "                     collection_name=\"FinancialData\", \n",
    "                     database_path=\"data/DB/vetorstore\", \n",
    "                     n_results=5):\n",
    "    # Initialize the client\n",
    "    client = chromadb.PersistentClient(database_path)\n",
    "    \n",
    "    # Get or create the collection\n",
    "    collection = client.get_or_create_collection(name=collection_name)\n",
    "    \n",
    "    # Query the collection with the provided answer\n",
    "    query_results = collection.query(\n",
    "        query_texts=[generated_answer],  # Text to query\n",
    "        n_results=n_results  # Number of results to retrieve\n",
    "    )\n",
    "    \n",
    "    # Display the query results\n",
    "    documents = query_results.get('documents')\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5><b>Execute</b></h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### Result ####################\n",
      "\n",
      "['SG&A, measured as a percent of sales, increased in 2022 when compared to the same period last year. SG&A was impacted by increased special item costs for significant\\nlitigation primarily related to steps toward resolving Combat Arms Earplugs litigation (discussed in Note 16) resulting in a 2022 second quarter pre-tax charge of approximately\\n$1.2 billion, certain impairment costs related to exiting PFAS manufacturing (see Note 15), costs related to exiting Russia (see Note 15), divestiture-related restructuring\\ncharges (see Note 5), and continued investment in key growth initiatives. These increases were partially offset by restructuring benefits and ongoing general 3M cost\\nmanagement.', 'Operating income for 2022 was $1.3 billion compared to operating income of $3.6 billion for 2021. The decrease in operating income was primarily driven by\\namortization of intangible assets associated with the Xilinx acquisition.', \"Results of Operations\\nAnalysis of Consolidated Sales\\nFor discussion on results of operations and financial condition pertaining to the fiscal years 2021 and 2020 see the Company’s Annual Report on Form 10-K for the fiscal year ended January 2, 2022, Item 7. Management's Discussion and Analysis of Results of Operations and Financial Condition.\\nIn 2022, worldwide sales increased 1.3% to $94.9 billion as compared to an increase of 13.6% in 2021. These sales changes consisted of the following:\\nSales increase/(decrease) due to:\\n2022\\n2021\\nVolume\\n6.9\\n%\\n12.9\\n%\\nPrice\\n(0.8)\\n(0.7)\\nCurrency\\n(4.8)\\n1.4\\nTotal\\n1.3\\n%\\n13.6\\n%\", '3M Company and Subsidiaries\\nConsolidated Balance Sheet\\n(Unaudited)\\n(Dollars in millions, except per share amount) June 30, 2023 December 31, 2022\\nAssets\\nCurrent assets\\nCash and cash equivalents $ 4,258 $ 3,655\\nMarketable securities — current 56 238\\nAccounts receivable — net of allowances of $160 and $174 4,947 4,532\\nInventories\\nFinished goods 2,526 2,497\\nWork in process 1,527 1,606\\nRaw materials and supplies 1,227 1,269\\nTotal inventories 5,280 5,372\\nPrepaids 674 435\\nOther current assets 539 456\\nTotal current assets 15,754 14,688\\nProperty, plant and equipment 26,459 25,998\\nLess: Accumulated depreciation (17,248) (16,820)\\nProperty, plant and equipment — net 9,211 9,178\\nOperating lease right of use assets 812 829\\nGoodwill 12,869 12,790\\nIntangible assets — net 4,470 4,699\\nOther assets 5,764 4,271\\nTotal assets $ 48,880 $ 46,455\\nLiabilities\\nCurrent liabilities\\nShort-term borrowings and current portion of long-term debt $ 3,033 $ 1,938\\nAccounts payable 3,231 3,183\\nAccrued payroll 785 692\\nAccrued income taxes 172 259\\nOperating lease liabilities — current 244 261\\nOther current liabilities 3,471 3,190\\nTotal current liabilities 10,936 9,523', 'Consolidated Statements of Operations\\nYears ended December 31, 2022, 2021, and 2020\\n2022 2021 2020\\n(in millions, except per share amounts)\\nRevenue:\\nRegulated $ 3,538 $ 2,868 $ 2,661\\nNon-Regulated 9,079 8,273 6,999\\nTotal revenue 12,617 11,141 9,660\\nCost of Sales:\\nRegulated (3,162) (2,448) (2,235)\\nNon-Regulated (6,907) (5,982) (4,732)\\nTotal cost of sales (10,069) (8,430) (6,967)\\nOperating margin 2,548 2,711 2,693\\nGeneral and administrative expenses (207) (166) (165)\\nInterest expense (1,117) (911) (1,038)\\nInterest income 389 298 268\\nLoss on extinguishment of debt (15) (78) (186)\\nOther expense (68) (60) (53)\\nOther income 102 410 75\\nLoss on disposal and sale of business interests (9) (1,683) (95)\\nGoodwill impairment expense (777) — —\\nAsset impairment expense (763) (1,575) (864)\\nForeign currency transaction gains (losses) (77) (10) 55\\nOther non-operating expense (175) — (202)\\nINCOME (LOSS) FROM CONTINUING OPERATIONS BEFORE TAXES AND EQUITY IN EARNINGS OF AFFILIATES (169) (1,064) 488\\nIncome tax benefit (expense) (265) 133 (216)\\nNet equity in losses of affiliates (71) (24) (123)\\nINCOME (LOSS) FROM CONTINUING OPERATIONS (505) (955) 149\\nGain from disposal of discontinued businesses, net of income tax expense of $0, $1, and $0, respectively — 4 3\\nNET INCOME (LOSS) (505) (951) 152\\nLess: Net loss (income) attributable to noncontrolling interests and redeemable stock of subsidiaries (41) 542 (106)\\nNET INCOME (LOSS) ATTRIBUTABLE TO THE AES CORPORATION $ (546) $ (409) $ 46']\n",
      "\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "query_results = query_collection(generated_answer)\n",
    "for query_result in query_results:\n",
    "    print(\"#################### Result ####################\")\n",
    "    print(f\"\\n{query_result}\\n\")\n",
    "    print(\"*************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
